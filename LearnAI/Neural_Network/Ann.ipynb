{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ANN from Scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron : \n",
    "    def __init__(self,num_inputs, learning_rate = 0.1):\n",
    "        # initalize weights with samell random value\n",
    "        self.weights = np.random.randn(num_inputs)\n",
    "        self.bias = np.random.randn()\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def activate(self, x):\n",
    "        # Apply step fun. to weigheted sum\n",
    "        _result = 0\n",
    "        if x>=0 : \n",
    "            _result=1\n",
    "            return _result\n",
    "        else :\n",
    "            return _result\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        # Compute weighted sum of inputs \n",
    "        weighted_sum = np.dot(inputs,self.weights) + self.bias\n",
    "        # Apply acivation function. \n",
    "        return self.activate(weighted_sum)\n",
    "    \n",
    "    def train(self, training_inputs, labels, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                error = label - prediction\n",
    "\n",
    "                # update weights and bias \n",
    "                self.weights += self.learning_rate * error * inputs \n",
    "                self.bias += self.learning_rate * error \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0 0], Prediction: 0\n",
      "Input: [0 1], Prediction: 0\n",
      "Input: [1 0], Prediction: 0\n",
      "Input: [1 1], Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels = np.array([0, 0, 0, 1])\n",
    "\n",
    "# Create a perceptron with 2 inputs\n",
    "perceptron = Perceptron(num_inputs=2)\n",
    "\n",
    "# Train the perceptron. \n",
    "perceptron.train(training_inputs, labels, num_epochs=10)\n",
    "\n",
    "# Test the percpetron \n",
    "\n",
    "test_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "for inputs in test_inputs:\n",
    "    prediction = perceptron.predict(inputs)\n",
    "    print(f\"Input: {inputs}, Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.74479293, 0.32636428])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_inputs = 2\n",
    "\n",
    "## Dot product for matrix multiplication. \n",
    "'''Ann.ipynb\n",
    "Bais term w0+ w1*x1 + w2*x2\n",
    "\n",
    "'''\n",
    "training_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "display(training_inputs.shape)\n",
    "weights = np.random.randn(num_inputs)\n",
    "display(weights.shape)\n",
    "display(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.29\n"
     ]
    }
   ],
   "source": [
    "inputs = [0.5, 0.8, 1.2]\n",
    "weights = [0.3, 0.4, 0.6]\n",
    "bias = 0.1\n",
    "\n",
    "result = np.dot(inputs,weights)  + bias   \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "does np.dot() automatically take care of matrix transpose ? how is the matrix multiplication impletemented in np.dot() ? give the algorithm and example code with numerical example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, `np.dot()` function in NumPy automatically handles the matrix transpose when performing matrix multiplication. The algorithm for matrix multiplication implemented in `np.dot()` follows the standard matrix multiplication algorithm, known as the dot product.\n",
    "\n",
    "Algorithm for Matrix Multiplication:\n",
    "1. Given two matrices `A` and `B` with appropriate dimensions, the resulting matrix `C` has dimensions `(m x p) = (m x n) * (n x p)`.\n",
    "2. Initialize an empty matrix `C` of shape `(m x p)` to store the result.\n",
    "3. For each element `C[i][j]` in matrix `C`:\n",
    "   - Compute the dot product of the `i`th row of matrix `A` and the `j`th column of matrix `B`.\n",
    "   - Sum the element-wise products of corresponding elements from the row of `A` and the column of `B` to obtain the dot product.\n",
    "   - Assign the dot product to the element `C[i][j]`.\n",
    "\n",
    "Here's an example code demonstrating matrix multiplication using `np.dot()` with a numerical example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Define matrices A and B\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "B = np.array([[7, 8],\n",
    "              [9, 10],\n",
    "              [11, 12]])\n",
    "\n",
    "# Perform matrix multiplication using np.dot()\n",
    "C = np.dot(A, B)\n",
    "\n",
    "# Print the result matrix C\n",
    "print(C)\n",
    "```\n",
    "\n",
    "Numerical Example:\n",
    "Suppose we have matrices `A` and `B` defined as shown above. The dimensions of matrices are `(2 x 3)` for `A` and `(3 x 2)` for `B`.\n",
    "\n",
    "The result of matrix multiplication `C = np.dot(A, B)` will be:\n",
    "\n",
    "```\n",
    "C = [[58, 64],\n",
    "     [139, 154]]\n",
    "```\n",
    "\n",
    "The element `C[0][0]` is computed as `(1 * 7) + (2 * 9) + (3 * 11) = 58`.\n",
    "Similarly, the other elements of matrix `C` are computed using the dot product of corresponding rows and columns.\n",
    "\n",
    "In this example, `np.dot()` automatically handles the matrix transpose, matching the dimensions of matrices `A` and `B` correctly for matrix multiplication.\n",
    "\n",
    "I hope this clarifies the algorithm and provides an example of matrix multiplication using `np.dot()` in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "## MLP XOR solution experiment. \n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define the XOR inputs and outputs\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Create and train an MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(2,), activation='relu', max_iter=10000)\n",
    "mlp.fit(X, y)\n",
    "\n",
    "# Test the trained MLP on XOR inputs\n",
    "predictions = mlp.predict(X)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
