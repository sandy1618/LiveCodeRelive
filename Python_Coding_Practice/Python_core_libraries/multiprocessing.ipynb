{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning about multiprocessing in Python is a great way to leverage multiple CPU cores and enhance the performance of your programs, especially for tasks that can be parallelized. I'll guide you through the basics of multiprocessing in Python, from fundamental concepts to more advanced topics.\n",
    "\n",
    "**1. Introduction to Multiprocessing:**\n",
    "\n",
    "Multiprocessing is a module in Python that allows you to create and manage multiple processes concurrently. It's particularly useful for CPU-bound tasks where the program's performance can be improved by distributing the work across multiple cores.\n",
    "\n",
    "**2. Basic Concepts:**\n",
    "\n",
    "- **Process Creation:** The `multiprocessing` module provides a `Process` class that allows you to create new processes. Each process runs in its own memory space and has its own Python interpreter.\n",
    "\n",
    "- **Process Communication:** Processes can communicate with each other through various mechanisms, such as pipes, queues, and shared memory.\n",
    "\n",
    "- **Pool of Workers:** The `Pool` class allows you to create a pool of worker processes that can execute a function concurrently.\n",
    "\n",
    "**3. Creating Processes:**\n",
    "\n",
    "You can create processes using the `Process` class from the `multiprocessing` module:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def worker_function():\n",
    "    print(\"Worker process\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process = multiprocessing.Process(target=worker_function)\n",
    "    process.start()\n",
    "    process.join()  # Wait for the process to finish\n",
    "```\n",
    "\n",
    "**4. Process Communication:**\n",
    "\n",
    "Processes can communicate using various methods such as `Queue` and `Pipe`. Here's an example using a `Queue`:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def worker_function(queue):\n",
    "    queue.put(\"Message from worker\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    queue = multiprocessing.Queue()\n",
    "    process = multiprocessing.Process(target=worker_function, args=(queue,))\n",
    "    process.start()\n",
    "    process.join()\n",
    "    \n",
    "    message = queue.get()\n",
    "    print(\"Parent received:\", message)\n",
    "```\n",
    "\n",
    "**5. Using Pool of Workers:**\n",
    "\n",
    "The `Pool` class provides a convenient way to manage a pool of worker processes:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def worker_function(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with multiprocessing.Pool(processes=4) as pool:\n",
    "        results = pool.map(worker_function, range(10))\n",
    "    print(results)\n",
    "```\n",
    "\n",
    "**6. Shared Memory:**\n",
    "\n",
    "The `multiprocessing` module also provides tools for sharing memory between processes, like `Value` and `Array`:\n",
    "\n",
    "```python\n",
    "import multiprocessing\n",
    "\n",
    "def worker_function(shared_value):\n",
    "    shared_value.value += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    shared_value = multiprocessing.Value(\"i\", 0)\n",
    "    process = multiprocessing.Process(target=worker_function, args=(shared_value,))\n",
    "    process.start()\n",
    "    process.join()\n",
    "    print(\"Shared value:\", shared_value.value)\n",
    "```\n",
    "\n",
    "**7. Advanced Concepts:**\n",
    "\n",
    "For more advanced use cases, you can explore topics like synchronization using `Lock`, using the `Manager` class for managing shared objects, and handling exceptions in multiprocessing code.\n",
    "\n",
    "Remember that due to Python's Global Interpreter Lock (GIL), multiprocessing is most effective for CPU-bound tasks. For I/O-bound tasks, consider using the `concurrent.futures` module with threads or asynchronous programming.\n",
    "\n",
    "As you delve deeper into multiprocessing, make sure to understand process synchronization, avoiding deadlocks, and managing resources effectively. Always refer to the official Python documentation for the most accurate and updated information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent received: Message from worker\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def worker_function(queue):\n",
    "    queue.put(\"Message from worker\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    queue = multiprocessing.Queue()\n",
    "    process = multiprocessing.Process(target=worker_function, args=(queue,))\n",
    "    process.start()\n",
    "    process.join()\n",
    "    \n",
    "    message = queue.get()\n",
    "    print(\"Parent received:\", message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "l = list(range(10)) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "def worker_function(x):\n",
    "    return x*x\n",
    "\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "results = pool.map(worker_function,l)\n",
    "pool.close()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def worker_function(x):\n",
    "    time.sleep(1)\n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "    results = pool.map(worker_function, range(10))\n",
    "    # Missing pool.close() and pool.join()\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 started.   Worker 1 started.   Worker 2 started.   Worker 3 started.   \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 1 finished.  Worker 0 finished.  Worker 3 finished.  \n",
      "Worker 4 started.   \n",
      "Worker 2 finished.  \n",
      "\n",
      "\n",
      "Worker 5 started.   \n",
      "Worker 7 started.   Worker 6 started.   \n",
      "\n",
      "Worker 4 finished.  \n",
      "Worker 8 started.   \n",
      "Worker 5 finished.  Worker 7 finished.  Worker 6 finished.  \n",
      "\n",
      "\n",
      "Worker 9 started.   \n",
      "Worker 8 finished.  \n",
      "Worker 9 finished.  \n",
      "All tasks submitted\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def worker_function(x):\n",
    "    print(f\"Worker {x} started.   \")\n",
    "    time.sleep(2)\n",
    "    print(f\"Worker {x} finished.  \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "    results = pool.map(worker_function, range(10))\n",
    "    # Missing pool.close() and pool.join()\n",
    "    print(\"All tasks submitted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why pool.close() is before pool.join() ? \n",
    "\n",
    "pool.close()\n",
    "pool.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why `pool.close()` is called before `pool.join()` is to allow new tasks to be submitted to the pool and prevent any more tasks from being added after the pool is closed.\n",
    "\n",
    "Here's the rationale behind this order:\n",
    "\n",
    "1. **Submitting Tasks:** When you call methods like `pool.map()` or `pool.apply_async()`, you're submitting tasks to the pool to be executed by the worker processes.\n",
    "\n",
    "2. **Closing the Pool:** After you've submitted all the tasks you want to run in parallel, you call `pool.close()`. This prevents any additional tasks from being added to the pool. At this point, the pool is still operational, and the worker processes will continue executing the tasks that have already been submitted.\n",
    "\n",
    "3. **Waiting for Completion:** After the pool is closed, you call `pool.join()`. This call blocks the main program's execution until all tasks submitted to the pool have been completed. This is necessary to ensure that your program doesn't proceed further until all the parallel tasks are finished.\n",
    "\n",
    "In summary, the order of `pool.close()` before `pool.join()` ensures that no more tasks are added to the pool after it's closed, and the `pool.join()` call blocks the main program until all submitted tasks are completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
